test_train_ratio: 0.2
data_validation_threshold: 0.05
missing_values: np.nan
n_neighbors: 2
target_column: "Result"
k_value: 10
list_of_models: ["Random Forest","Decision Tree","Gradient Boosting","Logistic Regression", "AdaBoost"]
max_iter: 1000
C: [0.01, 0.1, 1, 10]
penalty: ['l2']
solver': ['lbfgs', 'liblinear']
DecisionTree_max_iter: 100
DecisionTree_max_depth: [3, 5, 10, None]
DecisionTree_min_samples_split: [2, 5, 10]
DecisionTree_criterion: ['gini', 'entropy']
RandomForrest_n_estimators: [100, 200]
RandomForrest_max_depth: [None, 10, 20]
RandomForrest_min_samples_split: [2, 5]
RandomForrest_criterion: ['gini', 'entropy']
GradientBoosting_n_estimators: [100, 200]
GradientBoosting_learning_rate: [0.01, 0.1, 0.2]
GradientBoosting_max_depth: [3, 5]
AdaBoost_n_estimators: [50, 100, 200]
AdaBoost_learning_rate: [0.01, 0.1, 1]
cv: 5
scoring: 'recall'