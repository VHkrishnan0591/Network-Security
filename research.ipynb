{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629eea86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python-dotenv', 'numpy', 'pandas']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_documents(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    return lines \n",
    "\n",
    "l = parse_documents('requirements.txt')\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64c9595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSL handshake failed: ac-igeqnto-shard-00-01.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms),SSL handshake failed: ac-igeqnto-shard-00-02.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms),SSL handshake failed: ac-igeqnto-shard-00-00.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6830eb0bc52cd1033205cbe5, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('ac-igeqnto-shard-00-00.5pb4dm2.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-igeqnto-shard-00-00.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>, <ServerDescription ('ac-igeqnto-shard-00-01.5pb4dm2.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-igeqnto-shard-00-01.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>, <ServerDescription ('ac-igeqnto-shard-00-02.5pb4dm2.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-igeqnto-shard-00-02.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://harikrishnanv0591:c8hiZ5bohOzVRoj2@cluster0.5pb4dm2.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e990dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def csv_to_json(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11df215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_21684\\3405935831.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  records = csv_to_json('artifacts\\phisingData.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11055"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = csv_to_json('artifacts\\phisingData.csv')\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b03d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "def insert_data_mongodb(database_name, collection_name,filepath):\n",
    "    \n",
    "    load_dotenv()\n",
    "    uri = os.getenv(\"MONGO_DB_URL\") \n",
    "    \n",
    "    \n",
    "    # Create a new client and connect to the server\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "    database = client[database_name]\n",
    "    collection = database[collection_name]\n",
    "    records = csv_to_json(filepath)\n",
    "    collection.insert_many(records)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a6c867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_21684\\3591732485.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  insert_data_mongodb('Network_Security','Websites','artifacts\\phisingData.csv')\n"
     ]
    }
   ],
   "source": [
    "insert_data_mongodb('Network_Security','Websites','artifacts\\phisingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Name\":\"Alice\",\"Age\":25,\"City\":\"New York\"},{\"Name\":\"Bob\",\"Age\":30,\"City\":\"Los Angeles\"},{\"Name\":\"Charlie\",\"Age\":35,\"City\":\"Chicago\"}]\n",
      "[{'Name': 'Alice', 'Age': 25, 'City': 'New York'}, {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'}, {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "json_str = df.to_json(orient='records', )\n",
    "print(json_str)\n",
    "print(df.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2deb997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_21684\\3995628551.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  context = read_yaml('artifacts\\schema\\schema.yaml')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoxList([{'having_IP_Address': 'int64'}, {'URL_Length': 'int64'}, {'Shortining_Service': 'int64'}, {'having_At_Symbol': 'int64'}, {'double_slash_redirecting': 'int64'}, {'Prefix_Suffix': 'int64'}, {'having_Sub_Domain': 'int64'}, {'SSLfinal_State': 'int64'}, {'Domain_registeration_length': 'int64'}, {'Favicon': 'int64'}, {'port': 'int64'}, {'HTTPS_token': 'int64'}, {'Request_URL': 'int64'}, {'URL_of_Anchor': 'int64'}, {'Links_in_tags': 'int64'}, {'SFH': 'int64'}, {'Submitting_to_email': 'int64'}, {'Abnormal_URL': 'int64'}, {'Redirect': 'int64'}, {'on_mouseover': 'int64'}, {'RightClick': 'int64'}, {'popUpWidnow': 'int64'}, {'Iframe': 'int64'}, {'age_of_domain': 'int64'}, {'DNSRecord': 'int64'}, {'web_traffic': 'int64'}, {'Page_Rank': 'int64'}, {'Google_Index': 'int64'}, {'Links_pointing_to_page': 'int64'}, {'Statistical_report': 'int64'}, {'Result': 'int64'}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "from box import ConfigBox\n",
    "def read_yaml(path_to_yaml: str) -> ConfigBox:\n",
    "    try:\n",
    "        with open(path_to_yaml, 'r') as file:\n",
    "            content = yaml.safe_load(file)\n",
    "            return ConfigBox(content)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "context = read_yaml('artifacts\\schema\\schema.yaml')\n",
    "context.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aef7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'object'}, {'age': 'int64'}, {'salary': 'float64'}, {'is_manager': 'bool'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob'],\n",
    "    'age': [25, 30],\n",
    "    'salary': [50000.0, 60000.5],\n",
    "    'is_manager': [False, True]\n",
    "})\n",
    "\n",
    "# Get column names and data types\n",
    "column_info = [{col:str(dtype)} for col, dtype in df.dtypes.items()]\n",
    "print(column_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0c734d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [{'name': 'object'}, {'age': 'int64'}, {'salary': 'float64'}, {'is_manager': 'bool'}]\n",
    "if len(lst) == len(column_info):\n",
    "    for i in range(len(lst)):\n",
    "        key1, values1 = list(lst[i].items())[0]\n",
    "        key, value = list(column_info[i].items())[0]\n",
    "        if (key == key1)  and (value ==values1):\n",
    "            validation_status = True\n",
    "validation_status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f97632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_train_data.csv')\n",
    "X = df.drop(\"Result\",axis =1)\n",
    "Y = df['Result']\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# X: features, y: target\n",
    "selector = SelectKBest(score_func=f_classif, k=15)  # Select top 10 features\n",
    "X_new = selector.fit_transform(X, Y)\n",
    "\n",
    "# Get selected feature indices or names\n",
    "selected_features = selector.get_support(indices=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e50da9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  6,  7,  8, 12, 13, 14, 15, 23, 24, 25, 26, 27, 29])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70d02c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['having_IP_Address', 'URL_Length', 'Shortining_Service',\n",
       "       'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix',\n",
       "       'having_Sub_Domain', 'SSLfinal_State', 'Domain_registeration_length',\n",
       "       'Favicon', 'port', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor',\n",
       "       'Links_in_tags', 'SFH', 'Submitting_to_email', 'Abnormal_URL',\n",
       "       'Redirect', 'on_mouseover', 'RightClick', 'popUpWidnow', 'Iframe',\n",
       "       'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank',\n",
       "       'Google_Index', 'Links_pointing_to_page', 'Statistical_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bac6882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['having_IP_Address',\n",
       " 'Prefix_Suffix',\n",
       " 'having_Sub_Domain',\n",
       " 'SSLfinal_State',\n",
       " 'Domain_registeration_length',\n",
       " 'Request_URL',\n",
       " 'URL_of_Anchor',\n",
       " 'Links_in_tags',\n",
       " 'SFH',\n",
       " 'age_of_domain',\n",
       " 'DNSRecord',\n",
       " 'web_traffic',\n",
       " 'Page_Rank',\n",
       " 'Google_Index',\n",
       " 'Statistical_report']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [X.columns[i] for i in selected_features]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2a00ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Data Processing Specialist Assignment data ver 1.xlsx')\n",
    "duplicates = df.duplicated()\n",
    "print(type(duplicates))\n",
    "unique_count = duplicates.nunique()\n",
    "print(unique_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4218765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,f1_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa5f1115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "Accuracy: 0.9222071460877431\n",
      "Confusion Matrix:\n",
      " [[ 858   98]\n",
      " [  74 1181]]\n",
      "F1 Score: 0.9321231254932912\n",
      "Recall: 0.9410358565737051\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.90      0.91       956\n",
      "         1.0       0.92      0.94      0.93      1255\n",
      "\n",
      "    accuracy                           0.92      2211\n",
      "   macro avg       0.92      0.92      0.92      2211\n",
      "weighted avg       0.92      0.92      0.92      2211\n",
      "\n",
      "\n",
      "===== Decision Tree =====\n",
      "Accuracy: 0.9493441881501583\n",
      "Confusion Matrix:\n",
      " [[ 896   60]\n",
      " [  52 1203]]\n",
      "F1 Score: 0.9555202541699762\n",
      "Recall: 0.9585657370517928\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.94      0.94       956\n",
      "         1.0       0.95      0.96      0.96      1255\n",
      "\n",
      "    accuracy                           0.95      2211\n",
      "   macro avg       0.95      0.95      0.95      2211\n",
      "weighted avg       0.95      0.95      0.95      2211\n",
      "\n",
      "\n",
      "===== Random Forest =====\n",
      "Accuracy: 0.9574853007688828\n",
      "Confusion Matrix:\n",
      " [[ 898   58]\n",
      " [  36 1219]]\n",
      "F1 Score: 0.9628751974723538\n",
      "Recall: 0.9713147410358566\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.94      0.95       956\n",
      "         1.0       0.95      0.97      0.96      1255\n",
      "\n",
      "    accuracy                           0.96      2211\n",
      "   macro avg       0.96      0.96      0.96      2211\n",
      "weighted avg       0.96      0.96      0.96      2211\n",
      "\n",
      "\n",
      "===== Gradient Boosting =====\n",
      "Accuracy: 0.9461781999095432\n",
      "Confusion Matrix:\n",
      " [[ 888   68]\n",
      " [  51 1204]]\n",
      "F1 Score: 0.9529085872576177\n",
      "Recall: 0.9593625498007968\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.93      0.94       956\n",
      "         1.0       0.95      0.96      0.95      1255\n",
      "\n",
      "    accuracy                           0.95      2211\n",
      "   macro avg       0.95      0.94      0.95      2211\n",
      "weighted avg       0.95      0.95      0.95      2211\n",
      "\n",
      "\n",
      "===== AdaBoost =====\n",
      "Accuracy: 0.9312528267752148\n",
      "Confusion Matrix:\n",
      " [[ 869   87]\n",
      " [  65 1190]]\n",
      "F1 Score: 0.9399684044233807\n",
      "Recall: 0.9482071713147411\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.91      0.92       956\n",
      "         1.0       0.93      0.95      0.94      1255\n",
      "\n",
      "    accuracy                           0.93      2211\n",
      "   macro avg       0.93      0.93      0.93      2211\n",
      "weighted avg       0.93      0.93      0.93      2211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_train_data.csv')\n",
    "X_train = train_data.drop(columns='Result',axis=1)\n",
    "y_train = train_data['Result']\n",
    "test_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_test_data.csv')\n",
    "X_test = test_data.drop(columns='Result',axis=1)\n",
    "y_test = test_data['Result']\n",
    "X_train = X_train[columns]\n",
    "X_test = X_test[columns]\n",
    "\n",
    "# 3. Feature Scaling (important for Logistic Regression and boosting)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "metrics ={}\n",
    "\n",
    "# 5. Train, Predict, and Evaluate\n",
    "for name, model in models.items():\n",
    "    # Use scaled features for models that benefit from it\n",
    "    if name in [\"Logistic Regression\", \"Gradient Boosting\", \"AdaBoost\"]:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"Accuracy:\", (accuracy_score(y_test, y_pred)))\n",
    "    print(\"Confusion Matrix:\\n\", (confusion_matrix(y_test, y_pred)))\n",
    "    \n",
    "\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    print(\"Classification Report:\\n\", (classification_report(y_test, y_pred)))\n",
    "\n",
    "    metrics[name] = {'Accuracy':accuracy_score(y_test, y_pred),'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "                     \"F1 Score\": f1, \"Recall\": recall, \"Classification Report\":classification_report(y_test, y_pred)\n",
    "                     }\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f003f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "Accuracy: 0.924468566259611\n",
      "Confusion Matrix:\n",
      " [[ 865   91]\n",
      " [  76 1179]]\n",
      "F1 Score: 0.9338613861386139\n",
      "Recall: 0.9394422310756972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.90      0.91       956\n",
      "         1.0       0.93      0.94      0.93      1255\n",
      "\n",
      "    accuracy                           0.92      2211\n",
      "   macro avg       0.92      0.92      0.92      2211\n",
      "weighted avg       0.92      0.92      0.92      2211\n",
      "\n",
      "\n",
      "===== Decision Tree =====\n",
      "Accuracy: 0.9588421528720036\n",
      "Confusion Matrix:\n",
      " [[ 909   47]\n",
      " [  44 1211]]\n",
      "F1 Score: 0.9637883008356546\n",
      "Recall: 0.9649402390438248\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.95      0.95       956\n",
      "         1.0       0.96      0.96      0.96      1255\n",
      "\n",
      "    accuracy                           0.96      2211\n",
      "   macro avg       0.96      0.96      0.96      2211\n",
      "weighted avg       0.96      0.96      0.96      2211\n",
      "\n",
      "\n",
      "===== Random Forest =====\n",
      "Accuracy: 0.9678878335594754\n",
      "Confusion Matrix:\n",
      " [[ 909   47]\n",
      " [  24 1231]]\n",
      "F1 Score: 0.9719699960521121\n",
      "Recall: 0.9808764940239044\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.95      0.96       956\n",
      "         1.0       0.96      0.98      0.97      1255\n",
      "\n",
      "    accuracy                           0.97      2211\n",
      "   macro avg       0.97      0.97      0.97      2211\n",
      "weighted avg       0.97      0.97      0.97      2211\n",
      "\n",
      "\n",
      "===== Gradient Boosting =====\n",
      "Accuracy: 0.9507010402532791\n",
      "Confusion Matrix:\n",
      " [[ 891   65]\n",
      " [  44 1211]]\n",
      "F1 Score: 0.9569340181746345\n",
      "Recall: 0.9649402390438248\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.93      0.94       956\n",
      "         1.0       0.95      0.96      0.96      1255\n",
      "\n",
      "    accuracy                           0.95      2211\n",
      "   macro avg       0.95      0.95      0.95      2211\n",
      "weighted avg       0.95      0.95      0.95      2211\n",
      "\n",
      "\n",
      "===== AdaBoost =====\n",
      "Accuracy: 0.9298959746720941\n",
      "Confusion Matrix:\n",
      " [[ 872   84]\n",
      " [  71 1184]]\n",
      "F1 Score: 0.9385652001585414\n",
      "Recall: 0.9434262948207172\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.91      0.92       956\n",
      "         1.0       0.93      0.94      0.94      1255\n",
      "\n",
      "    accuracy                           0.93      2211\n",
      "   macro avg       0.93      0.93      0.93      2211\n",
      "weighted avg       0.93      0.93      0.93      2211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_train_data.csv')\n",
    "X_train = train_data.drop(columns='Result',axis=1)\n",
    "y_train = train_data['Result']\n",
    "test_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_test_data.csv')\n",
    "X_test = test_data.drop(columns='Result',axis=1)\n",
    "y_test = test_data['Result']\n",
    "\n",
    "# 3. Feature Scaling (important for Logistic Regression and boosting)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "metrics ={}\n",
    "\n",
    "# 5. Train, Predict, and Evaluate\n",
    "for name, model in models.items():\n",
    "    # Use scaled features for models that benefit from it\n",
    "    if name in [\"Logistic Regression\", \"Gradient Boosting\", \"AdaBoost\"]:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"Accuracy:\", (accuracy_score(y_test, y_pred)))\n",
    "    print(\"Confusion Matrix:\\n\", (confusion_matrix(y_test, y_pred)))\n",
    "    \n",
    "\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    print(\"Classification Report:\\n\", (classification_report(y_test, y_pred)))\n",
    "\n",
    "    metrics[name] = {'Accuracy':accuracy_score(y_test, y_pred),'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "                     \"F1 Score\": f1, \"Recall\": recall, \"Classification Report\":classification_report(y_test, y_pred)\n",
    "                     }\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa561465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'Accuracy': 0.924468566259611,\n",
       "  'Confusion Matrix': array([[ 865,   91],\n",
       "         [  76, 1179]]),\n",
       "  'F1 Score': 0.9338613861386139,\n",
       "  'Recall': 0.9394422310756972,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.92      0.90      0.91       956\\n         1.0       0.93      0.94      0.93      1255\\n\\n    accuracy                           0.92      2211\\n   macro avg       0.92      0.92      0.92      2211\\nweighted avg       0.92      0.92      0.92      2211\\n'},\n",
       " 'Decision Tree': {'Accuracy': 0.9592944369063772,\n",
       "  'Confusion Matrix': array([[ 909,   47],\n",
       "         [  43, 1212]]),\n",
       "  'F1 Score': 0.964200477326969,\n",
       "  'Recall': 0.9657370517928286,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.95      0.95      0.95       956\\n         1.0       0.96      0.97      0.96      1255\\n\\n    accuracy                           0.96      2211\\n   macro avg       0.96      0.96      0.96      2211\\nweighted avg       0.96      0.96      0.96      2211\\n'},\n",
       " 'Random Forest': {'Accuracy': 0.9674355495251018,\n",
       "  'Confusion Matrix': array([[ 910,   46],\n",
       "         [  26, 1229]]),\n",
       "  'F1 Score': 0.9715415019762846,\n",
       "  'Recall': 0.9792828685258964,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.97      0.95      0.96       956\\n         1.0       0.96      0.98      0.97      1255\\n\\n    accuracy                           0.97      2211\\n   macro avg       0.97      0.97      0.97      2211\\nweighted avg       0.97      0.97      0.97      2211\\n'},\n",
       " 'Gradient Boosting': {'Accuracy': 0.9507010402532791,\n",
       "  'Confusion Matrix': array([[ 891,   65],\n",
       "         [  44, 1211]]),\n",
       "  'F1 Score': 0.9569340181746345,\n",
       "  'Recall': 0.9649402390438248,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.95      0.93      0.94       956\\n         1.0       0.95      0.96      0.96      1255\\n\\n    accuracy                           0.95      2211\\n   macro avg       0.95      0.95      0.95      2211\\nweighted avg       0.95      0.95      0.95      2211\\n'},\n",
       " 'AdaBoost': {'Accuracy': 0.9298959746720941,\n",
       "  'Confusion Matrix': array([[ 872,   84],\n",
       "         [  71, 1184]]),\n",
       "  'F1 Score': 0.9385652001585414,\n",
       "  'Recall': 0.9434262948207172,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.92      0.91      0.92       956\\n         1.0       0.93      0.94      0.94      1255\\n\\n    accuracy                           0.93      2211\\n   macro avg       0.93      0.93      0.93      2211\\nweighted avg       0.93      0.93      0.93      2211\\n'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210fa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.9410358565737051,\n",
       " 'Decision Tree': 0.9585657370517928,\n",
       " 'Random Forest': 0.9713147410358566,\n",
       " 'Gradient Boosting': 0.9593625498007968,\n",
       " 'AdaBoost': 0.9482071713147411}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_recall_score = {}\n",
    "max =0\n",
    "for model_name, metric_values in metrics.items():\n",
    "    if metric_values['Recall'] > max:\n",
    "        s = model_name\n",
    "        max = metric_values['Recall']\n",
    "list_of_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b54fbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 0.9713147410358566}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_recall_score = {}\n",
    "max =0\n",
    "for model_name, metric_values in metrics.items():\n",
    "    if metric_values['Recall'] > max:\n",
    "        s = model_name\n",
    "        max = metric_values['Recall']\n",
    "list_of_recall_score[s] = max\n",
    "list_of_recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7311cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Dictionary to store best models\n",
    "best_models = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "param_logreg = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],  # 'l1' if solver='liblinear'\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "grid_logreg = GridSearchCV(LogisticRegression(max_iter=1000), param_logreg, cv=5, scoring='recall')\n",
    "grid_logreg.fit(X_train, y_train)\n",
    "best_models['Logistic Regression'] = grid_logreg.best_estimator_\n",
    "\n",
    "# 2. Decision Tree\n",
    "param_tree = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), param_tree, cv=5, scoring='recall')\n",
    "grid_tree.fit(X_train, y_train)\n",
    "best_models['Decision Tree'] = grid_tree.best_estimator_\n",
    "\n",
    "# 3. Random Forest\n",
    "param_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_rf, cv=5, scoring='recall')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_models['Random Forest'] = grid_rf.best_estimator_\n",
    "\n",
    "# 4. Gradient Boosting\n",
    "param_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "grid_gb = GridSearchCV(GradientBoostingClassifier(), param_gb, cv=5, scoring='recall')\n",
    "grid_gb.fit(X_train, y_train)\n",
    "best_models['Gradient Boosting'] = grid_gb.best_estimator_\n",
    "\n",
    "# 5. AdaBoost\n",
    "param_ada = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "grid_ada = GridSearchCV(AdaBoostClassifier(), param_ada, cv=5, scoring='accuracy')\n",
    "grid_ada.fit(X_train, y_train)\n",
    "best_models['AdaBoost'] = grid_ada.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b160bc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model - Logistic Regression\n",
      "F1 Score: 0.9348083761359146\n",
      "Recall: 0.9426294820717132\n",
      "Accuracy: 0.9253731343283582\n",
      "Best Params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best Model - Decision Tree\n",
      "F1 Score: 0.9365443425076453\n",
      "Recall: 0.9760956175298805\n",
      "Accuracy: 0.9249208502939846\n",
      "Best Params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n",
      "\n",
      "Best Model - Random Forest\n",
      "F1 Score: 0.9715639810426541\n",
      "Recall: 0.9800796812749004\n",
      "Accuracy: 0.9674355495251018\n",
      "Best Params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best Model - Gradient Boosting\n",
      "F1 Score: 0.9748031496062992\n",
      "Recall: 0.9864541832669322\n",
      "Accuracy: 0.9710538218000905\n",
      "Best Params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.2, 'loss': 'log_loss', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best Model - AdaBoost\n",
      "F1 Score: 0.9420575482853765\n",
      "Recall: 0.952191235059761\n",
      "Accuracy: 0.9335142469470827\n",
      "Best Params: {'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 1, 'n_estimators': 200, 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    if name in [\"Logistic Regression\", \"Gradient Boosting\", \"AdaBoost\"]:\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nBest Model - {name}\")\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Best Params:\", model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80df244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1.  1.  1.]\n",
      "0   -1.0\n",
      "1   -1.0\n",
      "2   -1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "test_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_test_data.csv')\n",
    "X_test = test_data[:5].drop(columns='Result',axis=1)\n",
    "y_test = test_data[:5]['Result']\n",
    "with open(r'artifacts\\model_directory\\best_model.pkl', 'rb') as file:\n",
    "            loaded_model = pickle.load(file)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3150e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "having_IP_Address has unique values [-1  1]\n",
      "URL_Length has unique values [ 1  0 -1]\n",
      "Shortining_Service has unique values [ 1 -1]\n",
      "having_At_Symbol has unique values [ 1 -1]\n",
      "double_slash_redirecting has unique values [-1  1]\n",
      "Prefix_Suffix has unique values [-1  1]\n",
      "having_Sub_Domain has unique values [-1  0  1]\n",
      "SSLfinal_State has unique values [-1  1  0]\n",
      "Domain_registeration_length has unique values [-1  1]\n",
      "Favicon has unique values [ 1 -1]\n",
      "port has unique values [ 1 -1]\n",
      "HTTPS_token has unique values [-1  1]\n",
      "Request_URL has unique values [ 1 -1]\n",
      "URL_of_Anchor has unique values [-1  0  1]\n",
      "Links_in_tags has unique values [ 1 -1  0]\n",
      "SFH has unique values [-1  1  0]\n",
      "Submitting_to_email has unique values [-1  1]\n",
      "Abnormal_URL has unique values [-1  1]\n",
      "Redirect has unique values [0 1]\n",
      "on_mouseover has unique values [ 1 -1]\n",
      "RightClick has unique values [ 1 -1]\n",
      "popUpWidnow has unique values [ 1 -1]\n",
      "Iframe has unique values [ 1 -1]\n",
      "age_of_domain has unique values [-1  1]\n",
      "DNSRecord has unique values [-1  1]\n",
      "web_traffic has unique values [-1  0  1]\n",
      "Page_Rank has unique values [-1  1]\n",
      "Google_Index has unique values [ 1 -1]\n",
      "Links_pointing_to_page has unique values [ 1  0 -1]\n",
      "Statistical_report has unique values [-1  1]\n",
      "Result has unique values [-1  1]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'artifacts\\data_ingestion_directory\\raw_data\\raw_data.csv')\n",
    "for i in data.columns:\n",
    "    print(f\"{i} has unique values {data[i].unique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
