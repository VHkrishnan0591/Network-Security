{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629eea86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python-dotenv', 'numpy', 'pandas']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_documents(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    return lines \n",
    "\n",
    "l = parse_documents('requirements.txt')\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64c9595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSL handshake failed: ac-igeqnto-shard-00-01.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms),SSL handshake failed: ac-igeqnto-shard-00-02.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms),SSL handshake failed: ac-igeqnto-shard-00-00.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 6830eb0bc52cd1033205cbe5, topology_type: ReplicaSetNoPrimary, servers: [<ServerDescription ('ac-igeqnto-shard-00-00.5pb4dm2.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-igeqnto-shard-00-00.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>, <ServerDescription ('ac-igeqnto-shard-00-01.5pb4dm2.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-igeqnto-shard-00-01.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>, <ServerDescription ('ac-igeqnto-shard-00-02.5pb4dm2.mongodb.net', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('SSL handshake failed: ac-igeqnto-shard-00-02.5pb4dm2.mongodb.net:27017: [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1000) (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://harikrishnanv0591:c8hiZ5bohOzVRoj2@cluster0.5pb4dm2.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e990dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def csv_to_json(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11df215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_21684\\3405935831.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  records = csv_to_json('artifacts\\phisingData.csv')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11055"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = csv_to_json('artifacts\\phisingData.csv')\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b03d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "def insert_data_mongodb(database_name, collection_name,filepath):\n",
    "    \n",
    "    load_dotenv()\n",
    "    uri = os.getenv(\"MONGO_DB_URL\") \n",
    "    \n",
    "    \n",
    "    # Create a new client and connect to the server\n",
    "    client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "    database = client[database_name]\n",
    "    collection = database[collection_name]\n",
    "    records = csv_to_json(filepath)\n",
    "    collection.insert_many(records)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5a6c867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_21684\\3591732485.py:1: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  insert_data_mongodb('Network_Security','Websites','artifacts\\phisingData.csv')\n"
     ]
    }
   ],
   "source": [
    "insert_data_mongodb('Network_Security','Websites','artifacts\\phisingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac90e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"Name\":\"Alice\",\"Age\":25,\"City\":\"New York\"},{\"Name\":\"Bob\",\"Age\":30,\"City\":\"Los Angeles\"},{\"Name\":\"Charlie\",\"Age\":35,\"City\":\"Chicago\"}]\n",
      "[{'Name': 'Alice', 'Age': 25, 'City': 'New York'}, {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'}, {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "json_str = df.to_json(orient='records', )\n",
    "print(json_str)\n",
    "print(df.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2deb997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_21684\\3995628551.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  context = read_yaml('artifacts\\schema\\schema.yaml')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BoxList([{'having_IP_Address': 'int64'}, {'URL_Length': 'int64'}, {'Shortining_Service': 'int64'}, {'having_At_Symbol': 'int64'}, {'double_slash_redirecting': 'int64'}, {'Prefix_Suffix': 'int64'}, {'having_Sub_Domain': 'int64'}, {'SSLfinal_State': 'int64'}, {'Domain_registeration_length': 'int64'}, {'Favicon': 'int64'}, {'port': 'int64'}, {'HTTPS_token': 'int64'}, {'Request_URL': 'int64'}, {'URL_of_Anchor': 'int64'}, {'Links_in_tags': 'int64'}, {'SFH': 'int64'}, {'Submitting_to_email': 'int64'}, {'Abnormal_URL': 'int64'}, {'Redirect': 'int64'}, {'on_mouseover': 'int64'}, {'RightClick': 'int64'}, {'popUpWidnow': 'int64'}, {'Iframe': 'int64'}, {'age_of_domain': 'int64'}, {'DNSRecord': 'int64'}, {'web_traffic': 'int64'}, {'Page_Rank': 'int64'}, {'Google_Index': 'int64'}, {'Links_pointing_to_page': 'int64'}, {'Statistical_report': 'int64'}, {'Result': 'int64'}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "from box import ConfigBox\n",
    "def read_yaml(path_to_yaml: str) -> ConfigBox:\n",
    "    try:\n",
    "        with open(path_to_yaml, 'r') as file:\n",
    "            content = yaml.safe_load(file)\n",
    "            return ConfigBox(content)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "context = read_yaml('artifacts\\schema\\schema.yaml')\n",
    "context.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aef7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'object'}, {'age': 'int64'}, {'salary': 'float64'}, {'is_manager': 'bool'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob'],\n",
    "    'age': [25, 30],\n",
    "    'salary': [50000.0, 60000.5],\n",
    "    'is_manager': [False, True]\n",
    "})\n",
    "\n",
    "# Get column names and data types\n",
    "column_info = [{col:str(dtype)} for col, dtype in df.dtypes.items()]\n",
    "print(column_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0c734d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [{'name': 'object'}, {'age': 'int64'}, {'salary': 'float64'}, {'is_manager': 'bool'}]\n",
    "if len(lst) == len(column_info):\n",
    "    for i in range(len(lst)):\n",
    "        key1, values1 = list(lst[i].items())[0]\n",
    "        key, value = list(column_info[i].items())[0]\n",
    "        if (key == key1)  and (value ==values1):\n",
    "            validation_status = True\n",
    "validation_status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f97632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_train_data.csv')\n",
    "X = df.drop(\"Result\",axis =1)\n",
    "Y = df['Result']\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# X: features, y: target\n",
    "selector = SelectKBest(score_func=f_classif, k=15)  # Select top 10 features\n",
    "X_new = selector.fit_transform(X, Y)\n",
    "\n",
    "# Get selected feature indices or names\n",
    "selected_features = selector.get_support(indices=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e50da9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  5,  6,  7,  8, 12, 13, 14, 15, 23, 24, 25, 26, 27, 29])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70d02c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['having_IP_Address', 'URL_Length', 'Shortining_Service',\n",
       "       'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix',\n",
       "       'having_Sub_Domain', 'SSLfinal_State', 'Domain_registeration_length',\n",
       "       'Favicon', 'port', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor',\n",
       "       'Links_in_tags', 'SFH', 'Submitting_to_email', 'Abnormal_URL',\n",
       "       'Redirect', 'on_mouseover', 'RightClick', 'popUpWidnow', 'Iframe',\n",
       "       'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank',\n",
       "       'Google_Index', 'Links_pointing_to_page', 'Statistical_report'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bac6882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['having_IP_Address',\n",
       " 'Prefix_Suffix',\n",
       " 'having_Sub_Domain',\n",
       " 'SSLfinal_State',\n",
       " 'Domain_registeration_length',\n",
       " 'Request_URL',\n",
       " 'URL_of_Anchor',\n",
       " 'Links_in_tags',\n",
       " 'SFH',\n",
       " 'age_of_domain',\n",
       " 'DNSRecord',\n",
       " 'web_traffic',\n",
       " 'Page_Rank',\n",
       " 'Google_Index',\n",
       " 'Statistical_report']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [X.columns[i] for i in selected_features]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2a00ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Data Processing Specialist Assignment data ver 1.xlsx')\n",
    "duplicates = df.duplicated()\n",
    "print(type(duplicates))\n",
    "unique_count = duplicates.nunique()\n",
    "print(unique_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4218765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,f1_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa5f1115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "Accuracy: 0.9222071460877431\n",
      "Confusion Matrix:\n",
      " [[ 858   98]\n",
      " [  74 1181]]\n",
      "F1 Score: 0.9321231254932912\n",
      "Recall: 0.9410358565737051\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.90      0.91       956\n",
      "         1.0       0.92      0.94      0.93      1255\n",
      "\n",
      "    accuracy                           0.92      2211\n",
      "   macro avg       0.92      0.92      0.92      2211\n",
      "weighted avg       0.92      0.92      0.92      2211\n",
      "\n",
      "\n",
      "===== Decision Tree =====\n",
      "Accuracy: 0.9493441881501583\n",
      "Confusion Matrix:\n",
      " [[ 896   60]\n",
      " [  52 1203]]\n",
      "F1 Score: 0.9555202541699762\n",
      "Recall: 0.9585657370517928\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.94      0.94       956\n",
      "         1.0       0.95      0.96      0.96      1255\n",
      "\n",
      "    accuracy                           0.95      2211\n",
      "   macro avg       0.95      0.95      0.95      2211\n",
      "weighted avg       0.95      0.95      0.95      2211\n",
      "\n",
      "\n",
      "===== Random Forest =====\n",
      "Accuracy: 0.9574853007688828\n",
      "Confusion Matrix:\n",
      " [[ 898   58]\n",
      " [  36 1219]]\n",
      "F1 Score: 0.9628751974723538\n",
      "Recall: 0.9713147410358566\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.96      0.94      0.95       956\n",
      "         1.0       0.95      0.97      0.96      1255\n",
      "\n",
      "    accuracy                           0.96      2211\n",
      "   macro avg       0.96      0.96      0.96      2211\n",
      "weighted avg       0.96      0.96      0.96      2211\n",
      "\n",
      "\n",
      "===== Gradient Boosting =====\n",
      "Accuracy: 0.9461781999095432\n",
      "Confusion Matrix:\n",
      " [[ 888   68]\n",
      " [  51 1204]]\n",
      "F1 Score: 0.9529085872576177\n",
      "Recall: 0.9593625498007968\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.93      0.94       956\n",
      "         1.0       0.95      0.96      0.95      1255\n",
      "\n",
      "    accuracy                           0.95      2211\n",
      "   macro avg       0.95      0.94      0.95      2211\n",
      "weighted avg       0.95      0.95      0.95      2211\n",
      "\n",
      "\n",
      "===== AdaBoost =====\n",
      "Accuracy: 0.9312528267752148\n",
      "Confusion Matrix:\n",
      " [[ 869   87]\n",
      " [  65 1190]]\n",
      "F1 Score: 0.9399684044233807\n",
      "Recall: 0.9482071713147411\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.93      0.91      0.92       956\n",
      "         1.0       0.93      0.95      0.94      1255\n",
      "\n",
      "    accuracy                           0.93      2211\n",
      "   macro avg       0.93      0.93      0.93      2211\n",
      "weighted avg       0.93      0.93      0.93      2211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_train_data.csv')\n",
    "X_train = train_data.drop(columns='Result',axis=1)\n",
    "y_train = train_data['Result']\n",
    "test_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_test_data.csv')\n",
    "X_test = test_data.drop(columns='Result',axis=1)\n",
    "y_test = test_data['Result']\n",
    "X_train = X_train[columns]\n",
    "X_test = X_test[columns]\n",
    "\n",
    "# 3. Feature Scaling (important for Logistic Regression and boosting)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "metrics ={}\n",
    "\n",
    "# 5. Train, Predict, and Evaluate\n",
    "for name, model in models.items():\n",
    "    # Use scaled features for models that benefit from it\n",
    "    if name in [\"Logistic Regression\", \"Gradient Boosting\", \"AdaBoost\"]:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"Accuracy:\", (accuracy_score(y_test, y_pred)))\n",
    "    print(\"Confusion Matrix:\\n\", (confusion_matrix(y_test, y_pred)))\n",
    "    \n",
    "\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    print(\"Classification Report:\\n\", (classification_report(y_test, y_pred)))\n",
    "\n",
    "    metrics[name] = {'Accuracy':accuracy_score(y_test, y_pred),'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "                     \"F1 Score\": f1, \"Recall\": recall, \"Classification Report\":classification_report(y_test, y_pred)\n",
    "                     }\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60f003f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Logistic Regression =====\n",
      "Accuracy: 0.924468566259611\n",
      "Confusion Matrix:\n",
      " [[ 865   91]\n",
      " [  76 1179]]\n",
      "F1 Score: 0.9338613861386139\n",
      "Recall: 0.9394422310756972\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.90      0.91       956\n",
      "         1.0       0.93      0.94      0.93      1255\n",
      "\n",
      "    accuracy                           0.92      2211\n",
      "   macro avg       0.92      0.92      0.92      2211\n",
      "weighted avg       0.92      0.92      0.92      2211\n",
      "\n",
      "\n",
      "===== Decision Tree =====\n",
      "Accuracy: 0.9588421528720036\n",
      "Confusion Matrix:\n",
      " [[ 909   47]\n",
      " [  44 1211]]\n",
      "F1 Score: 0.9637883008356546\n",
      "Recall: 0.9649402390438248\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.95      0.95       956\n",
      "         1.0       0.96      0.96      0.96      1255\n",
      "\n",
      "    accuracy                           0.96      2211\n",
      "   macro avg       0.96      0.96      0.96      2211\n",
      "weighted avg       0.96      0.96      0.96      2211\n",
      "\n",
      "\n",
      "===== Random Forest =====\n",
      "Accuracy: 0.9678878335594754\n",
      "Confusion Matrix:\n",
      " [[ 909   47]\n",
      " [  24 1231]]\n",
      "F1 Score: 0.9719699960521121\n",
      "Recall: 0.9808764940239044\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.97      0.95      0.96       956\n",
      "         1.0       0.96      0.98      0.97      1255\n",
      "\n",
      "    accuracy                           0.97      2211\n",
      "   macro avg       0.97      0.97      0.97      2211\n",
      "weighted avg       0.97      0.97      0.97      2211\n",
      "\n",
      "\n",
      "===== Gradient Boosting =====\n",
      "Accuracy: 0.9507010402532791\n",
      "Confusion Matrix:\n",
      " [[ 891   65]\n",
      " [  44 1211]]\n",
      "F1 Score: 0.9569340181746345\n",
      "Recall: 0.9649402390438248\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.95      0.93      0.94       956\n",
      "         1.0       0.95      0.96      0.96      1255\n",
      "\n",
      "    accuracy                           0.95      2211\n",
      "   macro avg       0.95      0.95      0.95      2211\n",
      "weighted avg       0.95      0.95      0.95      2211\n",
      "\n",
      "\n",
      "===== AdaBoost =====\n",
      "Accuracy: 0.9298959746720941\n",
      "Confusion Matrix:\n",
      " [[ 872   84]\n",
      " [  71 1184]]\n",
      "F1 Score: 0.9385652001585414\n",
      "Recall: 0.9434262948207172\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.92      0.91      0.92       956\n",
      "         1.0       0.93      0.94      0.94      1255\n",
      "\n",
      "    accuracy                           0.93      2211\n",
      "   macro avg       0.93      0.93      0.93      2211\n",
      "weighted avg       0.93      0.93      0.93      2211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_train_data.csv')\n",
    "X_train = train_data.drop(columns='Result',axis=1)\n",
    "y_train = train_data['Result']\n",
    "test_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_test_data.csv')\n",
    "X_test = test_data.drop(columns='Result',axis=1)\n",
    "y_test = test_data['Result']\n",
    "\n",
    "# 3. Feature Scaling (important for Logistic Regression and boosting)\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier()\n",
    "}\n",
    "metrics ={}\n",
    "\n",
    "# 5. Train, Predict, and Evaluate\n",
    "for name, model in models.items():\n",
    "    # Use scaled features for models that benefit from it\n",
    "    if name in [\"Logistic Regression\", \"Gradient Boosting\", \"AdaBoost\"]:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"Accuracy:\", (accuracy_score(y_test, y_pred)))\n",
    "    print(\"Confusion Matrix:\\n\", (confusion_matrix(y_test, y_pred)))\n",
    "    \n",
    "\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "\n",
    "    print(\"Classification Report:\\n\", (classification_report(y_test, y_pred)))\n",
    "\n",
    "    metrics[name] = {'Accuracy':accuracy_score(y_test, y_pred),'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "                     \"F1 Score\": f1, \"Recall\": recall, \"Classification Report\":classification_report(y_test, y_pred)\n",
    "                     }\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa561465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': {'Accuracy': 0.924468566259611,\n",
       "  'Confusion Matrix': array([[ 865,   91],\n",
       "         [  76, 1179]]),\n",
       "  'F1 Score': 0.9338613861386139,\n",
       "  'Recall': 0.9394422310756972,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.92      0.90      0.91       956\\n         1.0       0.93      0.94      0.93      1255\\n\\n    accuracy                           0.92      2211\\n   macro avg       0.92      0.92      0.92      2211\\nweighted avg       0.92      0.92      0.92      2211\\n'},\n",
       " 'Decision Tree': {'Accuracy': 0.9592944369063772,\n",
       "  'Confusion Matrix': array([[ 909,   47],\n",
       "         [  43, 1212]]),\n",
       "  'F1 Score': 0.964200477326969,\n",
       "  'Recall': 0.9657370517928286,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.95      0.95      0.95       956\\n         1.0       0.96      0.97      0.96      1255\\n\\n    accuracy                           0.96      2211\\n   macro avg       0.96      0.96      0.96      2211\\nweighted avg       0.96      0.96      0.96      2211\\n'},\n",
       " 'Random Forest': {'Accuracy': 0.9674355495251018,\n",
       "  'Confusion Matrix': array([[ 910,   46],\n",
       "         [  26, 1229]]),\n",
       "  'F1 Score': 0.9715415019762846,\n",
       "  'Recall': 0.9792828685258964,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.97      0.95      0.96       956\\n         1.0       0.96      0.98      0.97      1255\\n\\n    accuracy                           0.97      2211\\n   macro avg       0.97      0.97      0.97      2211\\nweighted avg       0.97      0.97      0.97      2211\\n'},\n",
       " 'Gradient Boosting': {'Accuracy': 0.9507010402532791,\n",
       "  'Confusion Matrix': array([[ 891,   65],\n",
       "         [  44, 1211]]),\n",
       "  'F1 Score': 0.9569340181746345,\n",
       "  'Recall': 0.9649402390438248,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.95      0.93      0.94       956\\n         1.0       0.95      0.96      0.96      1255\\n\\n    accuracy                           0.95      2211\\n   macro avg       0.95      0.95      0.95      2211\\nweighted avg       0.95      0.95      0.95      2211\\n'},\n",
       " 'AdaBoost': {'Accuracy': 0.9298959746720941,\n",
       "  'Confusion Matrix': array([[ 872,   84],\n",
       "         [  71, 1184]]),\n",
       "  'F1 Score': 0.9385652001585414,\n",
       "  'Recall': 0.9434262948207172,\n",
       "  'Classification Report': '              precision    recall  f1-score   support\\n\\n        -1.0       0.92      0.91      0.92       956\\n         1.0       0.93      0.94      0.94      1255\\n\\n    accuracy                           0.93      2211\\n   macro avg       0.93      0.93      0.93      2211\\nweighted avg       0.93      0.93      0.93      2211\\n'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d210fa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.9410358565737051,\n",
       " 'Decision Tree': 0.9585657370517928,\n",
       " 'Random Forest': 0.9713147410358566,\n",
       " 'Gradient Boosting': 0.9593625498007968,\n",
       " 'AdaBoost': 0.9482071713147411}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_recall_score = {}\n",
    "max =0\n",
    "for model_name, metric_values in metrics.items():\n",
    "    if metric_values['Recall'] > max:\n",
    "        s = model_name\n",
    "        max = metric_values['Recall']\n",
    "list_of_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b54fbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Random Forest': 0.9713147410358566}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_recall_score = {}\n",
    "max =0\n",
    "for model_name, metric_values in metrics.items():\n",
    "    if metric_values['Recall'] > max:\n",
    "        s = model_name\n",
    "        max = metric_values['Recall']\n",
    "list_of_recall_score[s] = max\n",
    "list_of_recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7311cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Dictionary to store best models\n",
    "best_models = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "param_logreg = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],  # 'l1' if solver='liblinear'\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "grid_logreg = GridSearchCV(LogisticRegression(max_iter=1000), param_logreg, cv=5, scoring='recall')\n",
    "grid_logreg.fit(X_train, y_train)\n",
    "best_models['Logistic Regression'] = grid_logreg.best_estimator_\n",
    "\n",
    "# 2. Decision Tree\n",
    "param_tree = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), param_tree, cv=5, scoring='recall')\n",
    "grid_tree.fit(X_train, y_train)\n",
    "best_models['Decision Tree'] = grid_tree.best_estimator_\n",
    "\n",
    "# 3. Random Forest\n",
    "param_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(), param_rf, cv=5, scoring='recall')\n",
    "grid_rf.fit(X_train, y_train)\n",
    "best_models['Random Forest'] = grid_rf.best_estimator_\n",
    "\n",
    "# 4. Gradient Boosting\n",
    "param_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "grid_gb = GridSearchCV(GradientBoostingClassifier(), param_gb, cv=5, scoring='recall')\n",
    "grid_gb.fit(X_train, y_train)\n",
    "best_models['Gradient Boosting'] = grid_gb.best_estimator_\n",
    "\n",
    "# 5. AdaBoost\n",
    "param_ada = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1]\n",
    "}\n",
    "grid_ada = GridSearchCV(AdaBoostClassifier(), param_ada, cv=5, scoring='accuracy')\n",
    "grid_ada.fit(X_train, y_train)\n",
    "best_models['AdaBoost'] = grid_ada.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b160bc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model - Logistic Regression\n",
      "F1 Score: 0.9348083761359146\n",
      "Recall: 0.9426294820717132\n",
      "Accuracy: 0.9253731343283582\n",
      "Best Params: {'C': 0.1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best Model - Decision Tree\n",
      "F1 Score: 0.9365443425076453\n",
      "Recall: 0.9760956175298805\n",
      "Accuracy: 0.9249208502939846\n",
      "Best Params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n",
      "\n",
      "Best Model - Random Forest\n",
      "F1 Score: 0.9715639810426541\n",
      "Recall: 0.9800796812749004\n",
      "Accuracy: 0.9674355495251018\n",
      "Best Params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best Model - Gradient Boosting\n",
      "F1 Score: 0.9748031496062992\n",
      "Recall: 0.9864541832669322\n",
      "Accuracy: 0.9710538218000905\n",
      "Best Params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.2, 'loss': 'log_loss', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best Model - AdaBoost\n",
      "F1 Score: 0.9420575482853765\n",
      "Recall: 0.952191235059761\n",
      "Accuracy: 0.9335142469470827\n",
      "Best Params: {'algorithm': 'deprecated', 'estimator': None, 'learning_rate': 1, 'n_estimators': 200, 'random_state': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    if name in [\"Logistic Regression\", \"Gradient Boosting\", \"AdaBoost\"]:\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\nBest Model - {name}\")\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Best Params:\", model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80df244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1.  1.  1.]\n",
      "0   -1.0\n",
      "1   -1.0\n",
      "2   -1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Result, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "test_data = pd.read_csv(r'artifacts\\data_transforamtion_directory\\transformed_test_data.csv')\n",
    "X_test = test_data[:5].drop(columns='Result',axis=1)\n",
    "y_test = test_data[:5]['Result']\n",
    "with open(r'artifacts\\model_directory\\best_model.pkl', 'rb') as file:\n",
    "            loaded_model = pickle.load(file)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3150e147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "having_IP_Address has unique values [-1  1]\n",
      "URL_Length has unique values [ 1  0 -1]\n",
      "Shortining_Service has unique values [ 1 -1]\n",
      "having_At_Symbol has unique values [ 1 -1]\n",
      "double_slash_redirecting has unique values [-1  1]\n",
      "Prefix_Suffix has unique values [-1  1]\n",
      "having_Sub_Domain has unique values [-1  0  1]\n",
      "SSLfinal_State has unique values [-1  1  0]\n",
      "Domain_registeration_length has unique values [-1  1]\n",
      "Favicon has unique values [ 1 -1]\n",
      "port has unique values [ 1 -1]\n",
      "HTTPS_token has unique values [-1  1]\n",
      "Request_URL has unique values [ 1 -1]\n",
      "URL_of_Anchor has unique values [-1  0  1]\n",
      "Links_in_tags has unique values [ 1 -1  0]\n",
      "SFH has unique values [-1  1  0]\n",
      "Submitting_to_email has unique values [-1  1]\n",
      "Abnormal_URL has unique values [-1  1]\n",
      "Redirect has unique values [0 1]\n",
      "on_mouseover has unique values [ 1 -1]\n",
      "RightClick has unique values [ 1 -1]\n",
      "popUpWidnow has unique values [ 1 -1]\n",
      "Iframe has unique values [ 1 -1]\n",
      "age_of_domain has unique values [-1  1]\n",
      "DNSRecord has unique values [-1  1]\n",
      "web_traffic has unique values [-1  0  1]\n",
      "Page_Rank has unique values [-1  1]\n",
      "Google_Index has unique values [ 1 -1]\n",
      "Links_pointing_to_page has unique values [ 1  0 -1]\n",
      "Statistical_report has unique values [-1  1]\n",
      "Result has unique values [-1  1]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'artifacts\\data_ingestion_directory\\raw_data\\raw_data.csv')\n",
    "for i in data.columns:\n",
    "    print(f\"{i} has unique values {data[i].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7d632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "# Example ground truth and predictions\n",
    "y_true = [0, 1, 0, 1]\n",
    "y_pred = [0, 0, 0, 1]\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Convert to a string format\n",
    "cm_text = '\\n'.join(['\\t'.join(map(str, row)) for row in cm])\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_text(cm_text, \"confusion_matrix.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c6b5eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "type(Path.cwd().joinpath(\"artifacts/mlruns\").as_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7400b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "\n",
    "# Set the tracking URI to the local mlruns directory\n",
    "mlflow.set_tracking_uri(uri =\"http://localhost:5000\")\n",
    "\n",
    "# Now load the model\n",
    "model = mlflow.sklearn.load_model(\"models:/best_model/latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b63cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Model Version: 7\n",
      "Run ID: d52f2d0fa9ce4cb3958ad491e9688019\n",
      "Source Path: file:///D:/Network%20Security%20Project/Network-Security/artifacts/mlruns/d52f2d0fa9ce4cb3958ad491e9688019/artifacts/Random Forest\n",
      "file:///D:/Network%20Security%20Project/Network-Security/artifacts/mlruns/d52f2d0fa9ce4cb3958ad491e9688019/artifacts/Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\AppData\\Local\\Temp\\ipykernel_57376\\4002227149.py:6: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = client.get_latest_versions(\"best_model\", stages=[\"None\", \"Production\", \"Staging\"])\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get latest version info for registered model\n",
    "latest_versions = client.get_latest_versions(\"best_model\", stages=[\"None\", \"Production\", \"Staging\"])\n",
    "print(len(latest_versions))\n",
    "\n",
    "for version in latest_versions:\n",
    "    print(\"Model Version:\", version.version)\n",
    "    print(\"Run ID:\", version.run_id)\n",
    "    print(\"Source Path:\", version.source)\n",
    "    s = version.source\n",
    "\n",
    "print(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fc3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\n",
    "    'having_IP_Address' : [-1 , 1],\n",
    "    'URL_Length' : [ 1,  0, -1],\n",
    "    'Shortining_Service' : [ 1, -1],\n",
    "    'having_At_Symbol' : [ 1, -1],\n",
    "    'double_slash_redirecting' : [-1,  1],\n",
    "    'Prefix_Suffix' : [-1,  1],\n",
    "    'having_Sub_Domain' : [-1,  0,  1],\n",
    "    'SSLfinal_State' : [-1,  1,  0],\n",
    "    'Domain_registeration_length' : [-1 , 1],\n",
    "    'Favicon' : [ 1, -1],\n",
    "    'port' : [ 1 ,-1],\n",
    "    'HTTPS_token' : [-1,  1],\n",
    "    'Request_URL' : [ 1 ,-1],\n",
    "    'URL_of_Anchor' : [-1,  0,  1],\n",
    "    'Links_in_tags' : [ 1 ,-1 , 0],\n",
    "    'SFH' : [-1  ,1  ,0],\n",
    "    'Submitting_to_email' : [-1 , 1],\n",
    "    'Abnormal_URL' : [-1 , 1],\n",
    "    'Redirect' : [0 ,1],\n",
    "    'on_mouseover' : [ 1 ,-1],\n",
    "    'RightClick' : [ 1 ,-1],\n",
    "    'popUpWidnow' : [ 1 -1],\n",
    "    'Iframe' : [ 1, -1],\n",
    "    'age_of_domain' : [-1  ,1],\n",
    "    'DNSRecord' : [-1  ,1],\n",
    "    'web_traffic' : [-1 , 0  ,1],\n",
    "    'Page_Rank' : [-1 , 1],\n",
    "    'Google_Index' : [ 1 ,-1],\n",
    "    'Links_pointing_to_page' : [ 1,  0, -1],\n",
    "    'Statistical_report' : [-1 , 1],\n",
    "    'Result' : [-1 , 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e20b51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 14:54:14.116 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-01 14:54:14.119 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-01 14:54:14.120 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# You can use a column just like st.sidebar:\u001b[39;00m\n\u001b[32m      7\u001b[39m dic = {\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhaving_IP_Address\u001b[39m\u001b[33m'\u001b[39m : [-\u001b[32m1\u001b[39m , \u001b[32m1\u001b[39m],\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mURL_Length\u001b[39m\u001b[33m'\u001b[39m : [ \u001b[32m1\u001b[39m,  \u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mLinks_pointing_to_page\u001b[39m\u001b[33m'\u001b[39m : [ \u001b[32m1\u001b[39m,  \u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m],\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mStatistical_report\u001b[39m\u001b[33m'\u001b[39m : [-\u001b[32m1\u001b[39m , \u001b[32m1\u001b[39m]}\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Network Security Project\\Network-Security\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Network Security Project\\Network-Security\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Network Security Project\\Network-Security\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Network Security Project\\Network-Security\\myenv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "left_column, right_column = st.columns(2)\n",
    "# You can use a column just like st.sidebar:\n",
    "\n",
    "\n",
    "dic = {\n",
    "    'having_IP_Address' : [-1 , 1],\n",
    "    'URL_Length' : [ 1,  0, -1],\n",
    "    'Shortining_Service' : [ 1, -1],\n",
    "    'having_At_Symbol' : [ 1, -1],\n",
    "    'double_slash_redirecting' : [-1,  1],\n",
    "    'Prefix_Suffix' : [-1,  1],\n",
    "    'having_Sub_Domain' : [-1,  0,  1],\n",
    "    'SSLfinal_State' : [-1,  1,  0],\n",
    "    'Domain_registeration_length' : [-1 , 1],\n",
    "    'Favicon' : [ 1, -1],\n",
    "    'port' : [ 1 ,-1],\n",
    "    'HTTPS_token' : [-1,  1],\n",
    "    'Request_URL' : [ 1 ,-1],\n",
    "    'URL_of_Anchor' : [-1,  0,  1],\n",
    "    'Links_in_tags' : [ 1 ,-1 , 0],\n",
    "    'SFH' : [-1  ,1  ,0],\n",
    "    'Submitting_to_email' : [-1 , 1],\n",
    "    'Abnormal_URL' : [-1 , 1],\n",
    "    'Redirect' : [0 ,1],\n",
    "    'on_mouseover' : [ 1 ,-1],\n",
    "    'RightClick' : [ 1 ,-1],\n",
    "    'popUpWidnow' : [ 1 -1],\n",
    "    'Iframe' : [ 1, -1],\n",
    "    'age_of_domain' : [-1  ,1],\n",
    "    'DNSRecord' : [-1  ,1],\n",
    "    'web_traffic' : [-1 , 0  ,1],\n",
    "    'Page_Rank' : [-1 , 1],\n",
    "    'Google_Index' : [ 1 ,-1],\n",
    "    'Links_pointing_to_page' : [ 1,  0, -1],\n",
    "    'Statistical_report' : [-1 , 1]}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "u can use a column just like st.sidebar:\n",
    "\n",
    "dic = {\n",
    "  'having_IP_Address' : ['No' , 'Yes'],\n",
    "  'URL_Length' : [ 'Yes', 'Not Found', 'No'],\n",
    "  'Shortining_Service' : [ 'Yes', 'No'],\n",
    "  'having_At_Symbol' : [ 'Yes', 'No'],\n",
    "  'double_slash_redirecting' : ['No', 'Yes'],\n",
    "  'Prefix_Suffix' : ['No', 'Yes'],\n",
    "  'having_Sub_Domain' : ['No', 'Not Found', 'Yes'],\n",
    "  'SSLfinal_State' : ['No', 'Yes', 'Not Found'],\n",
    "  'Domain_registeration_length' : ['No' , 'Yes'],\n",
    "  'Favicon' : [ 'Yes', 'No'],\n",
    "  'port' : [ 'Yes' ,'No'],\n",
    "  'HTTPS_token' : ['No', 'Yes'],\n",
    "  'Request_URL' : [ 'Yes' ,'No'],\n",
    "  'URL_of_Anchor' : ['No', 'Not Found', 'Yes'],\n",
    "  'Links_in_tags' : [ 'Yes' ,'No' , 'Not Found'],\n",
    "  'SFH' : ['No' ,'Yes' ,'Not Found'],\n",
    "  'Submitting_to_email' : ['No' , 'Yes'],\n",
    "  'Ab'No'rmal_URL' : ['No' , 'Yes'],\n",
    "  'Redirect' : ['Not Found' ,'Yes'],\n",
    "  'on_mouseover' : [ 'Yes' ,'No'],\n",
    "  'RightClick' : [ 'Yes' ,'No'],\n",
    "  'popUpWid'No'w' : [ 'Yes' 'No'],\n",
    "  'Iframe' : [ 'Yes', 'No'],\n",
    "  'age_of_domain' : ['No' ,'Yes'],\n",
    "  'DNSRecord' : ['No' ,'Yes'],\n",
    "  'web_traffic' : ['No' , 'Not Found' ,'Yes'],\n",
    "  'Page_Rank' : ['No' , 'Yes'],\n",
    "  'Google_Index' : [ 'Yes' ,'No'],\n",
    "  'Links_pointing_to_page' : [ 'Yes', 'Not Found', 'No'],\n",
    "  'Statistical_report' : ['No' , 'Yes']}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
